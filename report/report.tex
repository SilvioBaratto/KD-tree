\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{pdfpages}
\usepackage{eurosym}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{letltxmacro}
\usepackage{microtype}
\usepackage[left=3cm,right=3cm,bottom=3.5cm]{geometry}
\usepackage{emptypage}
\usepackage{amsmath,amssymb,amsthm, latexsym}
\usepackage[english,italian]{babel}
\usepackage{url}
\usepackage{caption}
\captionsetup{tableposition=top,figureposition=bottom,font=small,format=hang,labelfont={sf,bf}}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{hyphenat}
\pagestyle{empty}
\newcommand\AlCentroPagina[1]{%
\AddToShipoutPicture*{\AtPageCenter{%
\makebox(0,0){\includegraphics%
[width =0.9\paperwidth]{#1}}}}}

\begin{document}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}
\lstset{language=Java} 
\lstset{basicstyle=\footnotesize\ttfamily}
\author{Silvio Baratto}
\title{
\normalfont \normalsize 
\textsc{Università degli studi di trieste} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Assignment 2 KD-Tree\\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}
\maketitle
\tableofcontents
\newpage
\section{Introduction}
In computer science, a k-d dimensional tree is a space-partitioning data structure for organizing points in a k-dimensional space. k-d trees are a useful data structure for several applications, such as searches involving a multidimensional search key (e.g. range searches and nearest neighbor searches) and creating point clouds. k-d trees are a special case of binary space partitioning trees. In this brief report is presented a parallel implementations of k-d tree which uses two standard frameworks for parallel programming, namely OpenMP (shared memory) and MPI (distributed memory).
\section{Algorithm}
The construction of the tree is done by:
\begin{center}
\begin{itemize}
\item Finding median / pivot by medians of the input file. Each section of constant lenght is sorted bt nth element. \\
\item Recursively proceed on left and right portions on the left and right of the found median. Each median is a node. \\
\item Terminate when length of a portion is 0. \\
\item Return root node.
\end{itemize}
\end{center}
The time complexity of the divide and conquer algorithm is $O(nlog(n))$ since the partition process always picks the middle element as pivot. The median of the medias is found in linear time, $O(n)$.\\
Time complexity for partitioning n datapoints:
\begin{equation*}
T(n) = 2T(n / 2)+ \theta{(n)}
\end{equation*}
\subsection{Implementation}
The KD-Tree implementation was made with C++17 and written using C++ templates so is a generic programming algorithm working with both float, integers and double numbers. The purpose of this code was to be as simple as possible to use from the point of view of a user. The goal was to provide a k-d tree given only a filename of points choose from a local directory of the user. Because of this in the constructors of all the three classes (mpi, omp, serial) creates a non ordered vector of knodes using as points the ones in the dataset. In the implementation the tree is created from the vector, in this way it has been possible to use the standard library functions easily. \\
The implemented algorithm doesn’t use a sorting algorithm, but it uses the function provided by the standard
library “$std::nth\_element()$”. This function is a partial sorting algorithm that rearranges elements in [first,
last) such that:
\begin{center}
\begin{itemize}
\item the element pointed at by nth (the median) is changed to whatever element would occur in that position if [first, last) were sorted. \\
\item All of the elements before this new nth element (the median) are less than or equal to the elements after the new nth element. With this function, it’s possible to omit the implementation of a sorting algorithm because it has the best “worst expected running time”, that is $O(N)$. 
\end{itemize}
\end{center}
\begin{algorithm}[H]
\caption{makeTree}
\begin{algorithmic}[1]
\Function{makeTree}{begin, end, axis}
\If{$end <= begin$}\Comment{base case}
\State return $\textit{nullptr}$
\EndIf
\State $\textit{median} \gets begin + (end - begin) / 2$
\State $\Call{medianOfMedians}{$begin, med, axis$}$
\State $\textit{myaxis} \gets \text{round robin approach between 0 and 1}$
\State $knode[med].left \gets \Call{makeTree}{$begin, med, myaxis$}$
\State $knode[med].right \gets \Call{makeTree}{$med + 1, end, myaxis$}$
\State \Return \text{\&{knode[med]}}
\EndFunction
\end{algorithmic}
\end{algorithm}
\subsection{OpenMP}
OpenMP is one of the application programming interfaces that facilitates the employment of a shared memory paradigm for parallelization within a node. Below the algorithm used in the implementation
\begin{algorithm}[H]
\caption{makeTree}
\begin{algorithmic}[1]
\Function{makeTree}{begin, end, axis}
\If{$end <= begin$}\Comment{base case}
\State return $\textit{nullptr}$
\EndIf
\State $\textit{median} \gets begin + (end - begin) / 2$
\State $\Call{medianOfMedians}{$begin, med, axis$}$
\State $\textit{myaxis} \gets \text{round robin approach between 0 and 1}$
\color{blue}
\State{\#pragma omp task}
\color{black}
\State $knode[med].left \gets \Call{makeTree}{$begin, med, myaxis$}$
\color{blue}
\State{\#pragma omp task}
\color{black}
\State $knode[med].right \gets \Call{makeTree}{$med + 1, end, myaxis$}$
\State \Return \text{\&{knode[med]}}
\EndFunction
\Statex
\Function{makeTreeParallel}{begin, end, axis}
\State root
\color{blue}
\State{\#pragma omp parallel}
\State{\#pragma omp single}
\color{black}
\State $\textit{root} \gets \Call{makeTree}{$begin, end, axis$}$
\State \Return root
\EndFunction
\end{algorithmic}
\end{algorithm}
\subsection{OpenMPI}
The strategy used to implement the OpenMPI part was to divide for each process, a sub-tree that will be merged in only one process.\\
The process from the 1 to N construct a sub-tree to send at the main process. The work of the process 0 is primarly to merge all the sub-trees and to construct the final kd-tree. Untill a good level of the final tree is reached, the group of processes build the tree in a serial way. A good level is reached when the half of the number of process involved is equal to the power of 2 to level. When you get to this level, each process works alone creating in a serial way the sub-tree and send it to the master process, with the rank 0. There is a shared variable that assign the work of each process, that is has to work in the right or in the left. If the number of process is smaller that the number of the sub-tree that has to built, this variable automatically assign which process has to work two times. Meanwhile, there is the process with rank 0, that does the first part like others processes and then waits to receive the messagges with all of sub-trees.\\
The main problem of this implemented code with OpenMPI is that each sub-tree has to be serialized in a string before and deserialize the message received after.
\begin{algorithm}[H]
\caption{makeTreeParallel}
\begin{algorithmic}[1]
\Function{makeTree}{begin, end, axis}
\If{$depth == log2(nprocs)$}\Comment{base case}
\State return $\textit{nullptr}$
\EndIf
\State $\textit{median} \gets begin + (end - begin) / 2$
\State $\Call{medianOfMedians}{$begin, med, axis$}$
\State $\textit{myaxis} \gets \text{round robin approach between 0 and 1}$
\If{$rank != 0$}
\If{$depth == log2(nprocs)$}
\State depth $\gets$ depth + 1
\State $knode[med].left \gets \Call{makeTreeParallel}{$begin, med, myaxis, myaxis, nprocs, depth, comm, next$}$
\State next = next + 2
\State $knode[med].left \gets \Call{makeTree}{$med + 1, end, myaxis, nprocs, depth, comm, next$}$
\Else
\If{$rank == next$}
\State $knode[med].left \gets \Call{makeTree}{$begin, med, index$}$
\color{red}
\State $serializeLeft <- \Call{serializeNode}{$knode[med].left$}$
\color{black}
\color{blue}
\State $\textit{MPI\_Send({$serializeLeft, length, MPI\_CHAR, 0, left\_tag, comm$}})$
\color{black}
\color{red}
\State $serializeRight <- \Call{serializeNode}{$knode[med].right$}$
\color{black}
\color{blue}
\State $\textit{MPI\_Send({$serializeRight, length, MPI\_CHAR, 0, right\_tag, comm$}})$
\color{black}
\EndIf
\EndIf
\EndIf
\If($rank == 0$)
\If{$depth == log2(nprocs)$}
\State depth $\gets$ depth + 1
\State $knode[med].left \gets \Call{makeTreeParallel}{$begin, med, index, nprocs, depth, comm, rank$}$
\State next $\gets$ next + 2
\State $knode[med].right \gets \Call{makeTreeParallel}{$med + 1, end, index, nprocs, depth, comm, rank$}$
\Else 
\color{blue}
\State $\textit{MPI\_Probe({$next, left\_tag, comm, \&status$}})$
\State $\textit{MPI\_Get\_Count({$\&status, MPI\_CHAR, \&count$}})$
\State $\textit{MPI\_Recv({$buffer\_left, count MPI\_CHAR, next, left\_tag, comm, \&status$}})$
\color{red}
\State $knode[med].left <- \Call{deserializeParallel}{$buffer\_left$}$
\color{black}
\color{blue}
\State $\textit{MPI\_Probe({$next, right\_tag, comm, \&status$}})$
\State $\textit{MPI\_Get\_Count({$\&status, MPI\_CHAR, \&count$}})$
\State $\textit{MPI\_Recv({$buffer\_right, count MPI\_CHAR, next, left\_tag, comm, \&status$}})$
\color{red}
\State $knode[med].left <- \Call{deserializeParallel}{$buffer\_right$}$
\color{black}
\EndIf
\EndIf
\State \Return \text{\&{knode[med]}}
\EndFunction
\end{algorithmic}
\end{algorithm}
\section{Performance}
\section{Conclusion}
\end{document}
